receivers:
  jaeger:
    protocols:
      thrift_compact:
        endpoint: "0.0.0.0:6831"
      thrift_binary:
        endpoint: "0.0.0.0:6832"
      grpc:
        endpoint: "0.0.0.0:14250"
      thrift_http:
        endpoint: "0.0.0.0:14268"
  opencensus:
    endpoint: "0.0.0.0:55678"
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
      http:
        endpoint: "0.0.0.0:55681"
  zipkin:
    endpoint: "0.0.0.0:9411"
processors:
  ## The memory_limiter processor is used to prevent out of memory situations on the collector.
  memory_limiter:
    ## check_interval is the time between measurements of memory usage for the
    ## purposes of avoiding going over the limits. Defaults to zero, so no
    ## checks will be performed. Values below 1 second are not recommended since
    ## it can result in unnecessary CPU consumption.
    check_interval: 5s

    ## Maximum amount of memory, in MiB, targeted to be allocated by the process heap.
    ## Note that typically the total memory usage of process will be about 50MiB higher
    ## than this value.
    limit_mib: 1900

  ## The batch processor accepts spans and places them into batches grouped by node and resource
  batch:
    ## Number of spans after which a batch will be sent regardless of time
    send_batch_size: 256
    ## Never more than this many spans are being sent in a batch
    send_batch_max_size: 512
    ## Time duration after which a batch will be sent regardless of size
    timeout: 5s

  ## This processor allows to shape tracing traffic
  cascading_filter:
    ## (default = 30s): Wait time since the first span of a trace before making
    ## a filtering decision
    # decision_wait: 30s
    ## (default = 100000): Number of traces kept in memory. This number must be greater
	## than the number of traces which arrive within decision_wait time
    # num_traces: 200000

    ## 1. Pattern filtering
    ## Uncomment and Adjust the filters as needed
    # trace_reject_filters:
    #    - name: filter_out_pattern
    #      name_pattern: "/healtcheck" ## <- set to filter out spans with name matching this pattern

    ## 2. Probabilistic sampling  
    ## Uncomment and adjust the limit as needed
    # probabilistic_filtering_rate: 100 # <- output limit for this rule in spans/sec

    ## 3. Tail-based filtering
    ## Uncomment and adjust as needed
    trace_accept_filters:
      ## Adjust the duration threshold and limit as needed
      # - name: tail-based-duration
      #   properties:
      #     min_duration: 3s      ## <- traces longer then this will qualify to be sent
      #   spans_per_second: 500   ## <- output limit for this rule
      ## Adjust number of errors and limit as needed
      # - name: tail-based-errors
      #   properties:
      #     min_number_of_errors: 2 ## <- traces with at least this number of errors will qualify to be sent
      #   spans_per_second: 400     ## <- output limit for this rule
      ## Adjust number of errors and limit as needed
      # - name: tail-based-attributes
      #   attributes:               ## <- traces with at least one span or resource
      #     - key: service.name     ##    matching this attribute will qualify to be sent
      #       values:
      #         - login-service     ## <- pass all traces where at least one span belongs to "login-service" service
      #   spans_per_second: 300     ## <- output limit for this rule

extensions:
  health_check: {}
exporters:
  otlphttp:
    traces_endpoint: ENDPOINT_URL
  ## Following generates verbose logs with span content, useful to verify what
  ## metadata is being tagged. To enable, uncomment and add "logging" to exporters below.
  ## There are two levels that could be used: `debug` and `info` with the former
  ## being much more verbose and including (sampled) spans content
  # logging:
  #   loglevel: debug
service:
  extensions: [health_check]
  pipelines:
    traces:
      receivers: [jaeger, opencensus, otlp, zipkin]
      processors: [memory_limiter, cascading_filter, batch]
      exporters: [otlphttp]
